{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import zipfile\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dataset creation with 6 processes\n",
      "Found 500 images to process\n",
      "Using 6 processes for parallel processing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 500/500 [00:20<00:00, 24.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Dataset created with 21000 images:\n",
      "   - Class 0 (no marker): 3500 images\n",
      "   - Class 1 (with marker): 17500 images\n",
      "   - Output location: marker_detection_dataset\n",
      "Creating zip file: marker_detection_dataset.zip\n",
      "✅ Dataset compressed to: marker_detection_dataset.zip\n"
     ]
    }
   ],
   "source": [
    "input_path = \"./../data/food\"     # CHANGE this to your folder of food images\n",
    "output_root = \"marker_detection_dataset\"\n",
    "zip_output = \"marker_detection_dataset.zip\"\n",
    "\n",
    "def generate_marker(square_size=20, rows=6, cols=7, border=5):\n",
    "    \"\"\"Generate a color checkerboard marker pattern.\"\"\"\n",
    "    h, w = rows*square_size, cols*square_size\n",
    "    marker = np.ones((h, w, 3), dtype=np.uint8)*255\n",
    "    colors = [\n",
    "        (255,0,0),(0,255,0),(0,0,255),(255,255,0),(0,255,255),\n",
    "        (255,0,255),(128,128,128),(0,0,0),(0,128,255),(128,0,128)\n",
    "    ]\n",
    "    idx = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            tl = (j*square_size, i*square_size)\n",
    "            br = ((j+1)*square_size, (i+1)*square_size)\n",
    "            cv2.rectangle(marker, tl, br, colors[idx%len(colors)], -1)\n",
    "            idx += 1\n",
    "    return cv2.copyMakeBorder(marker, border, border, border, border, cv2.BORDER_CONSTANT, value=(0,0,0))\n",
    "\n",
    "def adjust_brightness_contrast(img, brightness=0, contrast=1.0):\n",
    "    \"\"\"Adjust brightness and contrast of an image.\"\"\"\n",
    "    return cv2.convertScaleAbs(img, alpha=contrast, beta=brightness)\n",
    "\n",
    "def adjust_white_balance(img, blue_gain=1.0, red_gain=1.0, green_gain=1.0):\n",
    "    \"\"\"Adjust color balance of an image.\"\"\"\n",
    "    b, g, r = cv2.split(img)\n",
    "    b = np.clip(b * blue_gain, 0, 255).astype(np.uint8)\n",
    "    g = np.clip(g * green_gain, 0, 255).astype(np.uint8)\n",
    "    r = np.clip(r * red_gain, 0, 255).astype(np.uint8)\n",
    "    return cv2.merge((b, g, r))\n",
    "\n",
    "def apply_shadow(img, intensity=0.5):\n",
    "    \"\"\"Apply a shadow gradient to an image.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    mask = np.ones((h, w), dtype=np.float32)\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            mask[i, j] = 1 - intensity * (i / h) * (j / w)\n",
    "    shadowed = img.astype(np.float32) * mask[:, :, np.newaxis]\n",
    "    return np.clip(shadowed, 0, 255).astype(np.uint8)\n",
    "\n",
    "def apply_filters(image):\n",
    "    \"\"\"Apply various lighting and color filters to an image.\"\"\"\n",
    "    filters = [\n",
    "        (\"Bright_Sunlight\", lambda img: adjust_brightness_contrast(img, brightness=50, contrast=1.2)),\n",
    "        (\"Overcast\", lambda img: adjust_brightness_contrast(img, brightness=-20, contrast=0.8)),\n",
    "        (\"Warm_Indoor\", lambda img: adjust_white_balance(img, blue_gain=0.9, red_gain=1.2)),\n",
    "        (\"Cool_Indoor\", lambda img: adjust_white_balance(img, blue_gain=1.2, red_gain=0.9)),\n",
    "        (\"Golden_Hour\", lambda img: adjust_white_balance(img, blue_gain=0.8, red_gain=1.3)),\n",
    "        (\"High_Contrast_Noon\", lambda img: adjust_brightness_contrast(img, brightness=30, contrast=1.5)),\n",
    "        (\"Soft_Morning\", lambda img: adjust_brightness_contrast(img, brightness=20, contrast=0.9)),\n",
    "    ]\n",
    "\n",
    "    filtered_images = []\n",
    "    for name, func in filters:\n",
    "        filtered = func(image.copy())\n",
    "        filtered = np.clip(filtered, 0, 255).astype(np.uint8)\n",
    "        filtered_images.append((name, filtered))\n",
    "    return filtered_images\n",
    "\n",
    "def overlay_marker(img):\n",
    "    \"\"\"Overlay a marker on an image at a random position.\"\"\"\n",
    "    marker = generate_marker()\n",
    "    h_img, w_img = img.shape[:2]\n",
    "    target_w = int(w_img * random.uniform(0.10, 0.15))\n",
    "    scale = target_w / marker.shape[1]\n",
    "    marker = cv2.resize(marker, (0, 0), fx=scale, fy=scale)\n",
    "    mh, mw = marker.shape[:2]\n",
    "\n",
    "    # Choose a random position (anywhere in the image with margin)\n",
    "    margin = 10\n",
    "    x = random.randint(margin, w_img - mw - margin)\n",
    "    y = random.randint(margin, h_img - mh - margin)\n",
    "\n",
    "    out = img.copy()\n",
    "    out[y:y+mh, x:x+mw] = marker\n",
    "    return out\n",
    "\n",
    "def zip_folder(folder_path, output_filename):\n",
    "    \"\"\"Compress the output folder into a zip file.\"\"\"\n",
    "    print(f\"Creating zip file: {output_filename}\")\n",
    "    with zipfile.ZipFile(output_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for root, _, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                arcname = os.path.relpath(file_path, os.path.dirname(folder_path))\n",
    "                zipf.write(file_path, arcname)\n",
    "    print(f\"✅ Dataset compressed to: {output_filename}\")\n",
    "\n",
    "def process_image(filename, input_folder, output_root):\n",
    "    \"\"\"Process a single image - this function will be run in parallel.\"\"\"\n",
    "    class0_dir = os.path.join(output_root, \"0\")\n",
    "    class1_dir = os.path.join(output_root, \"1\")\n",
    "    \n",
    "    # Skip non-image files\n",
    "    if not filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        return 0\n",
    "    \n",
    "    img_path = os.path.join(input_folder, filename)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return 0\n",
    "    \n",
    "    image_count = 0\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Create Class 0: Original image with filters\n",
    "    filtered_originals = apply_filters(img)\n",
    "    for filter_name, filtered_img in filtered_originals:\n",
    "        out_name = f\"{base_name}_{filter_name}.jpg\"\n",
    "        out_path = os.path.join(class0_dir, out_name)\n",
    "        cv2.imwrite(out_path, filtered_img)\n",
    "        image_count += 1\n",
    "    \n",
    "    # Create Class 1: Image with marker and filters\n",
    "    for marker_idx in range(5):  # Create 5 random marker positions per image\n",
    "        marked_img = overlay_marker(img)\n",
    "        filtered_marked = apply_filters(marked_img)\n",
    "        \n",
    "        for filter_name, filtered_img in filtered_marked:\n",
    "            out_name = f\"{base_name}_marker{marker_idx}_{filter_name}.jpg\"\n",
    "            out_path = os.path.join(class1_dir, out_name)\n",
    "            cv2.imwrite(out_path, filtered_img)\n",
    "            image_count += 1\n",
    "    \n",
    "    return image_count\n",
    "\n",
    "def create_marker_detection_dataset(input_folder, output_root, num_processes=None):\n",
    "    \"\"\"Create a dataset for marker detection with parallelization.\n",
    "    \n",
    "    Args:\n",
    "        input_folder: Path to folder containing original images\n",
    "        output_root: Path to output dataset folder\n",
    "        num_processes: Number of processes to use (defaults to CPU count)\n",
    "    \"\"\"\n",
    "    # Create directory structure\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    class0_dir = os.path.join(output_root, \"0\")\n",
    "    class1_dir = os.path.join(output_root, \"1\")\n",
    "    os.makedirs(class0_dir, exist_ok=True)\n",
    "    os.makedirs(class1_dir, exist_ok=True)\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_files = [f for f in os.listdir(input_folder) \n",
    "                  if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(\"❌ No images found in the input folder. Check the path.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    \n",
    "    # Determine number of processes to use\n",
    "    if num_processes is None:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "    print(f\"Using {num_processes} processes for parallel processing\")\n",
    "    \n",
    "    # Process images in parallel\n",
    "    with multiprocessing.Pool(processes=num_processes) as pool:\n",
    "        process_func = partial(process_image, input_folder=input_folder, output_root=output_root)\n",
    "        results = list(tqdm(pool.imap(process_func, image_files), \n",
    "                           total=len(image_files), \n",
    "                           desc=\"Processing images\"))\n",
    "    \n",
    "    # Calculate total processed images\n",
    "    total_images = sum(results)\n",
    "    \n",
    "    class0_count = len(os.listdir(class0_dir))\n",
    "    class1_count = len(os.listdir(class1_dir))\n",
    "    \n",
    "    print(f\"\\n✅ Dataset created with {total_images} images:\")\n",
    "    print(f\"   - Class 0 (no marker): {class0_count} images\")\n",
    "    print(f\"   - Class 1 (with marker): {class1_count} images\")\n",
    "    print(f\"   - Output location: {output_root}\")\n",
    "    \n",
    "    # Create zip file\n",
    "    zip_folder(output_root, zip_output)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get the number of available CPU cores\n",
    "    cpu_count = multiprocessing.cpu_count()\n",
    "    # Use 75% of available cores to avoid overloading the system\n",
    "    recommended_processes = max(1, int(cpu_count * 0.75))\n",
    "    \n",
    "    print(f\"Starting dataset creation with {recommended_processes} processes\")\n",
    "    create_marker_detection_dataset(\n",
    "        input_folder=input_path, \n",
    "        output_root=output_root, \n",
    "        num_processes=recommended_processes\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
